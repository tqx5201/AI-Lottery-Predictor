"""
AIå½©ç¥¨é¢„æµ‹ç³»ç»Ÿ - è‡ªåŠ¨æ•°æ®åˆ†ææ¨¡å—
æ™ºèƒ½åˆ†æå†å²å¼€å¥–æ•°æ®ï¼Œå‘ç°è§„å¾‹å’Œè¶‹åŠ¿
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from collections import Counter, defaultdict
import json
import math
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import functools
import hashlib
from multiprocessing import cpu_count

try:
    from core.database_manager import DatabaseManager
except ImportError:
    from ..core.database_manager import DatabaseManager

logger = logging.getLogger(__name__)


@dataclass
class AnalysisResult:
    """åˆ†æç»“æœæ•°æ®ç±»"""
    analysis_type: str
    confidence_score: float
    patterns: Dict[str, Any]
    recommendations: List[str]
    created_at: datetime


class LotteryAnalysis:
    """å½©ç¥¨æ•°æ®åˆ†æç±»"""
    
    def __init__(self, db_manager: DatabaseManager = None):
        """
        åˆå§‹åŒ–åˆ†ææ¨¡å—
        
        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
        """
        self.db_manager = db_manager or DatabaseManager()
        
        # æ€§èƒ½ä¼˜åŒ–é…ç½®
        self.max_workers = min(4, cpu_count())  # å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°
        self.cache_timeout_hours = 6  # ç¼“å­˜è¶…æ—¶æ—¶é—´
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.cache_max_size = 100  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        
        # å½©ç¥¨è§„åˆ™é…ç½®
        self.lottery_config = {
            "åŒè‰²çƒ": {
                "red_count": 6,
                "blue_count": 1,
                "red_range": (1, 33),
                "blue_range": (1, 16),
                "total_numbers": 7
            },
            "å¤§ä¹é€": {
                "front_count": 5,
                "back_count": 2,
                "front_range": (1, 35),
                "back_range": (1, 12),
                "total_numbers": 7
            }
        }
        
        # åˆ†ææƒé‡é…ç½®
        self.analysis_weights = {
            'frequency': 0.25,    # é¢‘ç‡åˆ†ææƒé‡
            'trend': 0.20,        # è¶‹åŠ¿åˆ†ææƒé‡
            'pattern': 0.20,      # å½¢æ€åˆ†ææƒé‡
            'missing': 0.15,      # é—æ¼åˆ†ææƒé‡
            'correlation': 0.10,  # ç›¸å…³æ€§åˆ†ææƒé‡
            'statistical': 0.10   # ç»Ÿè®¡åˆ†ææƒé‡
        }
    
    def comprehensive_analysis(self, lottery_type: str, period_range: str = "æœ€è¿‘100æœŸ",
                             force_refresh: bool = False, use_parallel: bool = True) -> Dict[str, Any]:
        """
        ç»¼åˆæ•°æ®åˆ†æ
        
        Args:
            lottery_type: å½©ç¥¨ç±»å‹
            period_range: æœŸæ•°èŒƒå›´
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°åˆ†æ
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        try:
            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            cache_key = self._generate_cache_key(lottery_type, period_range, 'comprehensive')
            if not force_refresh and cache_key in self.memory_cache:
                cached_data, cache_time = self.memory_cache[cache_key]
                if (datetime.now() - cache_time).total_seconds() < self.cache_timeout_hours * 3600:
                    logger.info(f"ä½¿ç”¨å†…å­˜ç¼“å­˜çš„ç»¼åˆåˆ†æç»“æœ: {lottery_type}")
                    return cached_data
            
            # æ£€æŸ¥æ•°æ®åº“ç¼“å­˜
            if not force_refresh:
                cached_result = self.db_manager.get_analysis_result(
                    lottery_type, 'comprehensive', period_range
                )
                if cached_result:
                    # æ›´æ–°å†…å­˜ç¼“å­˜
                    self._update_memory_cache(cache_key, cached_result)
                    logger.info(f"ä½¿ç”¨æ•°æ®åº“ç¼“å­˜çš„ç»¼åˆåˆ†æç»“æœ: {lottery_type}")
                    return cached_result
            
            # è·å–å†å²æ•°æ®
            history_data = self._get_history_data(lottery_type, period_range)
            
            if not history_data:
                logger.warning(f"å†å²æ•°æ®ä¸ºç©ºï¼Œè¿”å›åŸºç¡€åˆ†æç»“æœ: {lottery_type}")
                # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œè¿”å›åŸºç¡€çš„åˆ†æç»“æœè€Œä¸æ˜¯é”™è¯¯
                return {
                    'lottery_type': lottery_type,
                    'period_range': period_range,
                    'analysis_date': datetime.now().isoformat(),
                    'data_count': 0,
                    'confidence_score': 0.0,
                    'recommendations': ['æš‚æ— å†å²æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ·±åº¦åˆ†æ', 'å»ºè®®è·å–æ›´å¤šå†å²æ•°æ®åé‡è¯•'],
                    'scores': {
                        'regularity_score': 0.0,
                        'randomness_score': 50.0,
                        'hotness_score': 0.0,
                        'stability_score': 0.0,
                        'overall_score': 12.5
                    },
                    'error': 'æ— å†å²æ•°æ®'
                }
            
            # æ‰§è¡Œå„é¡¹åˆ†æï¼ˆæ”¯æŒå¹¶è¡Œå¤„ç†ï¼‰
            analysis_results = {}
            
            if use_parallel and len(history_data) > 50:  # æ•°æ®é‡è¾ƒå¤§æ—¶ä½¿ç”¨å¹¶è¡Œå¤„ç†
                analysis_results = self._parallel_analysis(history_data, lottery_type)
            else:
                # é¡ºåºæ‰§è¡Œåˆ†æ
                analysis_tasks = [
                    ('frequency', self._analyze_frequency),
                    ('trend', self._analyze_trend),
                    ('pattern', self._analyze_pattern),
                    ('missing', self._analyze_missing),
                    ('correlation', self._analyze_correlation),
                    ('statistical', self._analyze_statistical),
                    ('hot_cold', self._analyze_hot_cold),
                    ('sum_analysis', self._analyze_sum),
                    ('span', self._analyze_span),
                    ('consecutive', self._analyze_consecutive),
                    ('repeat', self._analyze_repeat),
                    ('distribution', self._analyze_distribution_advanced),  # æ–°å¢åˆ†æ
                    ('volatility', self._analyze_volatility),  # æ–°å¢åˆ†æ
                    ('cycle', self._analyze_cycle_patterns)  # æ–°å¢åˆ†æ
                ]
                
                for analysis_name, analysis_func in analysis_tasks:
                    try:
                        analysis_results[analysis_name] = analysis_func(history_data, lottery_type)
                    except Exception as e:
                        logger.error(f"{analysis_name}åˆ†æå¤±è´¥: {e}")
                        analysis_results[analysis_name] = {'error': str(e)}
            
            # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            confidence_score = self._calculate_comprehensive_confidence(analysis_results)
            
            # ç”Ÿæˆç»¼åˆå»ºè®®
            recommendations = self._generate_recommendations(analysis_results, lottery_type)
            
            # ç”Ÿæˆç»¼åˆè¯„åˆ†
            scores = self._calculate_comprehensive_scores(analysis_results)
            
            # æ•´åˆç»“æœ
            comprehensive_result = {
                'lottery_type': lottery_type,
                'period_range': period_range,
                'analysis_date': datetime.now().isoformat(),
                'data_count': len(history_data),
                'confidence_score': confidence_score,
                'recommendations': recommendations,
                'scores': scores,
                **analysis_results
            }
            
            # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“å’Œå†…å­˜ç¼“å­˜
            serializable_result = self._make_json_serializable(comprehensive_result)
            self.db_manager.save_analysis_result(
                lottery_type=lottery_type,
                analysis_type='comprehensive',
                period_range=period_range,
                analysis_data=serializable_result,
                confidence_score=confidence_score,
                expires_hours=self.cache_timeout_hours
            )
            
            # æ›´æ–°å†…å­˜ç¼“å­˜
            self._update_memory_cache(cache_key, comprehensive_result)
            
            logger.info(f"ç»¼åˆåˆ†æå®Œæˆ: {lottery_type}, ç½®ä¿¡åº¦: {confidence_score:.2f}")
            return comprehensive_result
            
        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {
                'error': f'åˆ†æå¤±è´¥: {str(e)}',
                'confidence_score': 0
            }
    
    def _get_history_data(self, lottery_type: str, period_range: str) -> List[Dict]:
        """è·å–å†å²æ•°æ®"""
        try:
            # è§£ææœŸæ•°èŒƒå›´
            period_map = {
                "æœ€è¿‘50æœŸ": 50,
                "æœ€è¿‘100æœŸ": 100,
                "æœ€è¿‘200æœŸ": 200,
                "æœ€è¿‘500æœŸ": 500,
                "æœ€è¿‘1000æœŸ": 1000
            }
            limit = period_map.get(period_range, 100)
            
            # ä»æ•°æ®åº“è·å–å†å²æ•°æ®
            history_records = self.db_manager.get_lottery_history(lottery_type, limit)
            
            if not history_records:
                logger.warning(f"æœªè·å–åˆ°å†å²æ•°æ®: {lottery_type} {period_range}")
                # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨ä½†ä¸å½±å“å…¶ä»–åˆ†æ
                return []
            
            return history_records
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _analyze_frequency(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """é¢‘ç‡åˆ†æ"""
        try:
            config = self.lottery_config[lottery_type]
            
            if lottery_type == "åŒè‰²çƒ":
                red_freq = Counter()
                blue_freq = Counter()
                
                for record in history_data:
                    numbers = record.get('numbers', {})
                    if isinstance(numbers, str):
                        numbers = json.loads(numbers)
                    
                    red_nums = numbers.get('red', '').split(',')
                    blue_num = numbers.get('blue', '')
                    
                    for num in red_nums:
                        if num.strip().isdigit():
                            red_freq[int(num.strip())] += 1
                    
                    if blue_num.strip().isdigit():
                        blue_freq[int(blue_num.strip())] += 1
                
                return {
                    'red_frequency': dict(red_freq),
                    'blue_frequency': dict(blue_freq),
                    'hot_red': red_freq.most_common(10),
                    'cold_red': red_freq.most_common()[-10:],
                    'hot_blue': blue_freq.most_common(5),
                    'cold_blue': blue_freq.most_common()[-5:],
                    'analysis_quality': 'high' if len(history_data) >= 100 else 'medium'
                }
            
            else:  # å¤§ä¹é€
                front_freq = Counter()
                back_freq = Counter()
                
                for record in history_data:
                    numbers = record.get('numbers', {})
                    if isinstance(numbers, str):
                        numbers = json.loads(numbers)
                    
                    front_nums = numbers.get('front', '').split(',')
                    back_nums = numbers.get('back', '').split(',')
                    
                    for num in front_nums:
                        if num.strip().isdigit():
                            front_freq[int(num.strip())] += 1
                    
                    for num in back_nums:
                        if num.strip().isdigit():
                            back_freq[int(num.strip())] += 1
                
                return {
                    'front_frequency': dict(front_freq),
                    'back_frequency': dict(back_freq),
                    'hot_front': front_freq.most_common(10),
                    'cold_front': front_freq.most_common()[-10:],
                    'hot_back': back_freq.most_common(5),
                    'cold_back': back_freq.most_common()[-5:],
                    'analysis_quality': 'high' if len(history_data) >= 100 else 'medium'
                }
                
        except Exception as e:
            logger.error(f"é¢‘ç‡åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_trend(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """è¶‹åŠ¿åˆ†æ"""
        try:
            if len(history_data) < 20:
                return {'error': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ'}
            
            trends = {
                'increasing_numbers': [],
                'decreasing_numbers': [],
                'stable_numbers': [],
                'trend_strength': 0.0
            }
            
            # åˆ†ææœ€è¿‘20æœŸçš„è¶‹åŠ¿
            recent_data = history_data[:20]
            
            if lottery_type == "åŒè‰²çƒ":
                # åˆ†æçº¢çƒè¶‹åŠ¿
                red_trends = defaultdict(list)
                
                for i, record in enumerate(recent_data):
                    numbers = record.get('numbers', {})
                    if isinstance(numbers, str):
                        numbers = json.loads(numbers)
                    
                    red_nums = numbers.get('red', '').split(',')
                    for num in red_nums:
                        if num.strip().isdigit():
                            red_trends[int(num.strip())].append(i)
                
                # è®¡ç®—è¶‹åŠ¿
                for num, positions in red_trends.items():
                    if len(positions) >= 3:
                        # è®¡ç®—è¶‹åŠ¿æ–œç‡
                        x = np.array(positions)
                        y = np.arange(len(positions))
                        slope, _, r_value, _, _ = stats.linregress(x, y)
                        
                        if slope < -0.1 and r_value < -0.5:
                            trends['increasing_numbers'].append((num, abs(slope)))
                        elif slope > 0.1 and r_value > 0.5:
                            trends['decreasing_numbers'].append((num, slope))
                        else:
                            trends['stable_numbers'].append((num, slope))
            
            else:  # å¤§ä¹é€
                # ç±»ä¼¼çš„é€»è¾‘å¤„ç†å¤§ä¹é€å‰åŒºå’ŒååŒº
                pass
            
            # è®¡ç®—è¶‹åŠ¿å¼ºåº¦
            total_numbers = len(trends['increasing_numbers']) + len(trends['decreasing_numbers']) + len(trends['stable_numbers'])
            if total_numbers > 0:
                trends['trend_strength'] = (len(trends['increasing_numbers']) + len(trends['decreasing_numbers'])) / total_numbers
            
            return trends
            
        except Exception as e:
            logger.error(f"è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_pattern(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """å½¢æ€åˆ†æï¼ˆå¥‡å¶ã€å¤§å°ã€è´¨åˆç­‰ï¼‰"""
        try:
            patterns = {
                'odd_even_distribution': {},
                'big_small_distribution': {},
                'prime_composite_distribution': {},
                'pattern_frequency': {}
            }
            
            config = self.lottery_config[lottery_type]
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    
                    if len(red_nums) == 6:
                        # å¥‡å¶åˆ†æ
                        odd_count = sum(1 for num in red_nums if num % 2 == 1)
                        even_count = 6 - odd_count
                        odd_even_pattern = f"{odd_count}å¥‡{even_count}å¶"
                        patterns['odd_even_distribution'][odd_even_pattern] = patterns['odd_even_distribution'].get(odd_even_pattern, 0) + 1
                        
                        # å¤§å°åˆ†æ
                        big_count = sum(1 for num in red_nums if num > 16.5)
                        small_count = 6 - big_count
                        big_small_pattern = f"{big_count}å¤§{small_count}å°"
                        patterns['big_small_distribution'][big_small_pattern] = patterns['big_small_distribution'].get(big_small_pattern, 0) + 1
                        
                        # è´¨åˆåˆ†æ
                        primes = {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31}
                        prime_count = sum(1 for num in red_nums if num in primes)
                        composite_count = 6 - prime_count
                        prime_pattern = f"{prime_count}è´¨{composite_count}åˆ"
                        patterns['prime_composite_distribution'][prime_pattern] = patterns['prime_composite_distribution'].get(prime_pattern, 0) + 1
                
                else:  # å¤§ä¹é€
                    front_nums = [int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()]
                    
                    if len(front_nums) == 5:
                        # ç±»ä¼¼çš„åˆ†æé€»è¾‘
                        pass
            
            # æ‰¾å‡ºæœ€å¸¸è§çš„å½¢æ€æ¨¡å¼
            patterns['most_common_odd_even'] = max(patterns['odd_even_distribution'].items(), key=lambda x: x[1]) if patterns['odd_even_distribution'] else None
            patterns['most_common_big_small'] = max(patterns['big_small_distribution'].items(), key=lambda x: x[1]) if patterns['big_small_distribution'] else None
            
            return patterns
            
        except Exception as e:
            logger.error(f"å½¢æ€åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_missing(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """é—æ¼åˆ†æ"""
        try:
            config = self.lottery_config[lottery_type]
            missing_analysis = {}
            
            if lottery_type == "åŒè‰²çƒ":
                # åˆ†æçº¢çƒå’Œè“çƒçš„é—æ¼æƒ…å†µ
                red_missing = {i: 0 for i in range(1, 34)}
                blue_missing = {i: 0 for i in range(1, 17)}
                
                red_last_appear = {i: len(history_data) for i in range(1, 34)}
                blue_last_appear = {i: len(history_data) for i in range(1, 17)}
                
                for idx, record in enumerate(history_data):
                    numbers = record.get('numbers', {})
                    if isinstance(numbers, str):
                        numbers = json.loads(numbers)
                    
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    blue_num = numbers.get('blue', '')
                    
                    # æ›´æ–°çº¢çƒé—æ¼
                    for num in red_nums:
                        if num in red_last_appear:
                            red_missing[num] = idx - red_last_appear[num] + 1
                            red_last_appear[num] = idx
                    
                    # æ›´æ–°è“çƒé—æ¼
                    if blue_num.strip().isdigit():
                        blue_int = int(blue_num.strip())
                        if blue_int in blue_last_appear:
                            blue_missing[blue_int] = idx - blue_last_appear[blue_int] + 1
                            blue_last_appear[blue_int] = idx
                
                # è®¡ç®—å½“å‰é—æ¼å€¼
                current_red_missing = {num: len(history_data) - red_last_appear[num] for num in range(1, 34)}
                current_blue_missing = {num: len(history_data) - blue_last_appear[num] for num in range(1, 17)}
                
                missing_analysis = {
                    'red_missing': current_red_missing,
                    'blue_missing': current_blue_missing,
                    'max_red_missing': max(current_red_missing.values()),
                    'max_blue_missing': max(current_blue_missing.values()),
                    'high_missing_red': [num for num, missing in current_red_missing.items() if missing > 20],
                    'high_missing_blue': [num for num, missing in current_blue_missing.items() if missing > 10]
                }
            
            else:  # å¤§ä¹é€
                # ç±»ä¼¼çš„é€»è¾‘å¤„ç†å¤§ä¹é€
                pass
            
            return missing_analysis
            
        except Exception as e:
            logger.error(f"é—æ¼åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_correlation(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """ç›¸å…³æ€§åˆ†æ"""
        try:
            if len(history_data) < 50:
                return {'error': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ'}
            
            correlation_analysis = {}
            
            # æ„å»ºæ•°æ®çŸ©é˜µ
            data_matrix = []
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    if len(red_nums) == 6:
                        # åˆ›å»ºå·ç å‘é‡ï¼ˆ1-33çš„äºŒè¿›åˆ¶è¡¨ç¤ºï¼‰
                        vector = [1 if i in red_nums else 0 for i in range(1, 34)]
                        data_matrix.append(vector)
                
                else:  # å¤§ä¹é€
                    front_nums = [int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()]
                    if len(front_nums) == 5:
                        # åˆ›å»ºå‰åŒºå·ç å‘é‡
                        vector = [1 if i in front_nums else 0 for i in range(1, 36)]
                        data_matrix.append(vector)
            
            if len(data_matrix) >= 20:
                # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
                df = pd.DataFrame(data_matrix)
                corr_matrix = df.corr()
                
                # æ‰¾å‡ºé«˜ç›¸å…³æ€§çš„å·ç å¯¹
                high_correlations = []
                for i in range(len(corr_matrix)):
                    for j in range(i+1, len(corr_matrix)):
                        corr_value = corr_matrix.iloc[i, j]
                        if abs(corr_value) > 0.3:  # ç›¸å…³æ€§é˜ˆå€¼
                            high_correlations.append({
                                'number1': i + 1,
                                'number2': j + 1,
                                'correlation': corr_value
                            })
                
                correlation_analysis = {
                    'high_correlations': high_correlations,
                    'correlation_strength': 'high' if len(high_correlations) > 10 else 'low',
                    'most_correlated_pairs': sorted(high_correlations, key=lambda x: abs(x['correlation']), reverse=True)[:5]
                }
            
            return correlation_analysis
            
        except Exception as e:
            logger.error(f"ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_statistical(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """ç»Ÿè®¡å­¦åˆ†æ"""
        try:
            statistical_analysis = {}
            
            # æ”¶é›†æ•°æ®
            all_numbers = []
            sums = []
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    if len(red_nums) == 6:
                        all_numbers.extend(red_nums)
                        sums.append(sum(red_nums))
                
                else:  # å¤§ä¹é€
                    front_nums = [int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()]
                    if len(front_nums) == 5:
                        all_numbers.extend(front_nums)
                        sums.append(sum(front_nums))
            
            if all_numbers and sums:
                # åŸºæœ¬ç»Ÿè®¡
                statistical_analysis = {
                    'mean': np.mean(all_numbers),
                    'median': np.median(all_numbers),
                    'std': np.std(all_numbers),
                    'variance': np.var(all_numbers),
                    'sum_mean': np.mean(sums),
                    'sum_std': np.std(sums),
                    'sum_range': (min(sums), max(sums)),
                    'distribution_type': self._analyze_distribution(all_numbers)
                }
                
                # æ­£æ€æ€§æ£€éªŒ
                if len(all_numbers) > 50:
                    _, p_value = stats.normaltest(all_numbers)
                    statistical_analysis['normality_p_value'] = p_value
                    statistical_analysis['is_normal'] = p_value > 0.05
            
            return statistical_analysis
            
        except Exception as e:
            logger.error(f"ç»Ÿè®¡å­¦åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_distribution(self, numbers: List[int]) -> str:
        """åˆ†ææ•°å­—åˆ†å¸ƒç±»å‹"""
        try:
            # ç®€å•çš„åˆ†å¸ƒç±»å‹åˆ¤æ–­
            mean_val = np.mean(numbers)
            median_val = np.median(numbers)
            
            if abs(mean_val - median_val) < 1:
                return "è¿‘ä¼¼æ­£æ€åˆ†å¸ƒ"
            elif mean_val > median_val:
                return "å³ååˆ†å¸ƒ"
            else:
                return "å·¦ååˆ†å¸ƒ"
                
        except:
            return "æœªçŸ¥åˆ†å¸ƒ"
    
    def _analyze_hot_cold(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """å†·çƒ­å·åˆ†æ"""
        try:
            frequency_result = self._analyze_frequency(history_data, lottery_type)
            
            if 'error' in frequency_result:
                return frequency_result
            
            hot_cold_analysis = {}
            
            if lottery_type == "åŒè‰²çƒ":
                red_freq = frequency_result.get('red_frequency', {})
                blue_freq = frequency_result.get('blue_frequency', {})
                
                # è®¡ç®—å¹³å‡é¢‘ç‡
                avg_red_freq = np.mean(list(red_freq.values())) if red_freq else 0
                avg_blue_freq = np.mean(list(blue_freq.values())) if blue_freq else 0
                
                # åˆ†ç±»å†·çƒ­å·
                hot_red = [num for num, freq in red_freq.items() if freq > avg_red_freq * 1.2]
                cold_red = [num for num, freq in red_freq.items() if freq < avg_red_freq * 0.8]
                hot_blue = [num for num, freq in blue_freq.items() if freq > avg_blue_freq * 1.2]
                cold_blue = [num for num, freq in blue_freq.items() if freq < avg_blue_freq * 0.8]
                
                hot_cold_analysis = {
                    'hot': {
                        'red': hot_red,
                        'blue': hot_blue
                    },
                    'cold': {
                        'red': cold_red,
                        'blue': cold_blue
                    },
                    'avg_frequency': {
                        'red': avg_red_freq,
                        'blue': avg_blue_freq
                    }
                }
            
            else:  # å¤§ä¹é€
                front_freq = frequency_result.get('front_frequency', {})
                back_freq = frequency_result.get('back_frequency', {})
                
                avg_front_freq = np.mean(list(front_freq.values())) if front_freq else 0
                avg_back_freq = np.mean(list(back_freq.values())) if back_freq else 0
                
                hot_front = [num for num, freq in front_freq.items() if freq > avg_front_freq * 1.2]
                cold_front = [num for num, freq in front_freq.items() if freq < avg_front_freq * 0.8]
                hot_back = [num for num, freq in back_freq.items() if freq > avg_back_freq * 1.2]
                cold_back = [num for num, freq in back_freq.items() if freq < avg_back_freq * 0.8]
                
                hot_cold_analysis = {
                    'hot': {
                        'front': hot_front,
                        'back': hot_back
                    },
                    'cold': {
                        'front': cold_front,
                        'back': cold_back
                    },
                    'avg_frequency': {
                        'front': avg_front_freq,
                        'back': avg_back_freq
                    }
                }
            
            return hot_cold_analysis
            
        except Exception as e:
            logger.error(f"å†·çƒ­å·åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_sum(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """å’Œå€¼åˆ†æ"""
        try:
            sums = []
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    if len(red_nums) == 6:
                        sums.append(sum(red_nums))
                
                else:  # å¤§ä¹é€
                    front_nums = [int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()]
                    if len(front_nums) == 5:
                        sums.append(sum(front_nums))
            
            if not sums:
                return {'error': 'æ— æœ‰æ•ˆå’Œå€¼æ•°æ®'}
            
            # å’Œå€¼ç»Ÿè®¡åˆ†æ
            sum_analysis = {
                'recent_sums': sums[:20],  # æœ€è¿‘20æœŸå’Œå€¼
                'mean_sum': np.mean(sums),
                'median_sum': np.median(sums),
                'min_sum': min(sums),
                'max_sum': max(sums),
                'std_sum': np.std(sums),
                'sum_distribution': dict(Counter(sums)),
                'sum_trend': 'increasing' if len(sums) > 10 and np.corrcoef(range(10), sums[:10])[0,1] > 0.3 else 'stable'
            }
            
            # å’Œå€¼åŒºé—´åˆ†æ
            if lottery_type == "åŒè‰²çƒ":
                # åŒè‰²çƒçº¢çƒå’Œå€¼ç†è®ºèŒƒå›´ï¼š21-183
                ranges = {
                    'low': (21, 90),
                    'medium': (91, 140),
                    'high': (141, 183)
                }
            else:
                # å¤§ä¹é€å‰åŒºå’Œå€¼ç†è®ºèŒƒå›´ï¼š15-155
                ranges = {
                    'low': (15, 70),
                    'medium': (71, 120),
                    'high': (121, 155)
                }
            
            range_counts = {range_name: 0 for range_name in ranges.keys()}
            for sum_val in sums:
                for range_name, (min_val, max_val) in ranges.items():
                    if min_val <= sum_val <= max_val:
                        range_counts[range_name] += 1
                        break
            
            sum_analysis['range_distribution'] = range_counts
            
            return sum_analysis
            
        except Exception as e:
            logger.error(f"å’Œå€¼åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_span(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """è·¨åº¦åˆ†æ"""
        try:
            spans = []
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = [int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()]
                    if len(red_nums) == 6:
                        spans.append(max(red_nums) - min(red_nums))
                
                else:  # å¤§ä¹é€
                    front_nums = [int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()]
                    if len(front_nums) == 5:
                        spans.append(max(front_nums) - min(front_nums))
            
            if not spans:
                return {'error': 'æ— æœ‰æ•ˆè·¨åº¦æ•°æ®'}
            
            span_analysis = {
                'recent_spans': spans[:20],
                'mean_span': np.mean(spans),
                'median_span': np.median(spans),
                'min_span': min(spans),
                'max_span': max(spans),
                'std_span': np.std(spans),
                'span_distribution': dict(Counter(spans))
            }
            
            # è·¨åº¦åŒºé—´åˆ†æ
            span_ranges = {
                'small': (0, 15),
                'medium': (16, 25),
                'large': (26, 35)
            }
            
            range_counts = {range_name: 0 for range_name in span_ranges.keys()}
            for span in spans:
                for range_name, (min_val, max_val) in span_ranges.items():
                    if min_val <= span <= max_val:
                        range_counts[range_name] += 1
                        break
            
            span_analysis['range_distribution'] = range_counts
            
            return span_analysis
            
        except Exception as e:
            logger.error(f"è·¨åº¦åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_consecutive(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """è¿å·åˆ†æ"""
        try:
            consecutive_counts = []
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = sorted([int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()])
                    if len(red_nums) == 6:
                        consecutive_count = self._count_consecutive(red_nums)
                        consecutive_counts.append(consecutive_count)
                
                else:  # å¤§ä¹é€
                    front_nums = sorted([int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()])
                    if len(front_nums) == 5:
                        consecutive_count = self._count_consecutive(front_nums)
                        consecutive_counts.append(consecutive_count)
            
            if not consecutive_counts:
                return {'error': 'æ— æœ‰æ•ˆè¿å·æ•°æ®'}
            
            consecutive_analysis = {
                'consecutive_distribution': dict(Counter(consecutive_counts)),
                'avg_consecutive': np.mean(consecutive_counts),
                'max_consecutive': max(consecutive_counts),
                'no_consecutive_rate': consecutive_counts.count(0) / len(consecutive_counts) * 100
            }
            
            return consecutive_analysis
            
        except Exception as e:
            logger.error(f"è¿å·åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _count_consecutive(self, numbers: List[int]) -> int:
        """è®¡ç®—è¿å·ä¸ªæ•°"""
        if len(numbers) < 2:
            return 0
        
        consecutive_count = 0
        current_count = 1
        
        for i in range(1, len(numbers)):
            if numbers[i] == numbers[i-1] + 1:
                current_count += 1
            else:
                if current_count >= 2:
                    consecutive_count += current_count
                current_count = 1
        
        if current_count >= 2:
            consecutive_count += current_count
        
        return consecutive_count
    
    def _analyze_repeat(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """é‡å·åˆ†æï¼ˆä¸ä¸ŠæœŸé‡å¤çš„å·ç ï¼‰"""
        try:
            repeat_counts = []
            
            prev_numbers = None
            
            for record in history_data:
                numbers = record.get('numbers', {})
                if isinstance(numbers, str):
                    numbers = json.loads(numbers)
                
                if lottery_type == "åŒè‰²çƒ":
                    red_nums = set([int(num.strip()) for num in numbers.get('red', '').split(',') if num.strip().isdigit()])
                    
                    if prev_numbers is not None and len(red_nums) == 6:
                        repeat_count = len(red_nums & prev_numbers)
                        repeat_counts.append(repeat_count)
                    
                    if len(red_nums) == 6:
                        prev_numbers = red_nums
                
                else:  # å¤§ä¹é€
                    front_nums = set([int(num.strip()) for num in numbers.get('front', '').split(',') if num.strip().isdigit()])
                    
                    if prev_numbers is not None and len(front_nums) == 5:
                        repeat_count = len(front_nums & prev_numbers)
                        repeat_counts.append(repeat_count)
                    
                    if len(front_nums) == 5:
                        prev_numbers = front_nums
            
            if not repeat_counts:
                return {'error': 'æ— æœ‰æ•ˆé‡å·æ•°æ®'}
            
            repeat_analysis = {
                'repeat_distribution': dict(Counter(repeat_counts)),
                'avg_repeat': np.mean(repeat_counts),
                'max_repeat': max(repeat_counts),
                'no_repeat_rate': repeat_counts.count(0) / len(repeat_counts) * 100
            }
            
            return repeat_analysis
            
        except Exception as e:
            logger.error(f"é‡å·åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _calculate_comprehensive_confidence(self, analysis_results: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆç½®ä¿¡åº¦"""
        try:
            confidence_scores = []
            
            # æ ¹æ®å„é¡¹åˆ†æçš„å®Œæ•´æ€§å’Œè´¨é‡è®¡ç®—ç½®ä¿¡åº¦
            for analysis_type, weight in self.analysis_weights.items():
                if analysis_type in analysis_results:
                    result = analysis_results[analysis_type]
                    if 'error' not in result:
                        # æ ¹æ®åˆ†æç±»å‹è®¡ç®—å…·ä½“ç½®ä¿¡åº¦
                        if analysis_type == 'frequency':
                            quality = result.get('analysis_quality', 'medium')
                            score = 0.9 if quality == 'high' else 0.7
                        elif analysis_type == 'statistical':
                            score = 0.8 if 'mean' in result else 0.5
                        else:
                            score = 0.7  # é»˜è®¤åˆ†æ•°
                        
                        confidence_scores.append(score * weight)
            
            overall_confidence = sum(confidence_scores) / sum(self.analysis_weights.values()) * 100
            return round(overall_confidence, 2)
            
        except Exception as e:
            logger.error(f"è®¡ç®—ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return 50.0  # é»˜è®¤ç½®ä¿¡åº¦
    
    def _generate_recommendations(self, analysis_results: Dict[str, Any], lottery_type: str) -> List[str]:
        """ç”Ÿæˆåˆ†æå»ºè®®"""
        recommendations = []
        
        try:
            # åŸºäºé¢‘ç‡åˆ†æçš„å»ºè®®
            if 'frequency' in analysis_results and 'error' not in analysis_results['frequency']:
                freq_result = analysis_results['frequency']
                if lottery_type == "åŒè‰²çƒ":
                    hot_red = freq_result.get('hot_red', [])
                    cold_red = freq_result.get('cold_red', [])
                    if hot_red:
                        recommendations.append(f"è€ƒè™‘å…³æ³¨çƒ­é—¨çº¢çƒå·ç : {[num for num, _ in hot_red[:5]]}")
                    if cold_red:
                        recommendations.append(f"å…³æ³¨å†·é—¨çº¢çƒå·ç çš„è¡¥å‡ºæœºä¼š: {[num for num, _ in cold_red[:3]]}")
            
            # åŸºäºé—æ¼åˆ†æçš„å»ºè®®
            if 'missing' in analysis_results and 'error' not in analysis_results['missing']:
                missing_result = analysis_results['missing']
                high_missing = missing_result.get('high_missing_red', [])
                if high_missing:
                    recommendations.append(f"é‡ç‚¹å…³æ³¨é«˜é—æ¼å·ç : {high_missing[:3]}")
            
            # åŸºäºå½¢æ€åˆ†æçš„å»ºè®®
            if 'pattern' in analysis_results and 'error' not in analysis_results['pattern']:
                pattern_result = analysis_results['pattern']
                common_odd_even = pattern_result.get('most_common_odd_even')
                if common_odd_even:
                    recommendations.append(f"å»ºè®®é‡‡ç”¨å¸¸è§å¥‡å¶å½¢æ€: {common_odd_even[0]}")
            
            # åŸºäºå’Œå€¼åˆ†æçš„å»ºè®®
            if 'sum_analysis' in analysis_results and 'error' not in analysis_results['sum_analysis']:
                sum_result = analysis_results['sum_analysis']
                mean_sum = sum_result.get('mean_sum', 0)
                if mean_sum > 0:
                    recommendations.append(f"å»ºè®®é€‰æ‹©å’Œå€¼åœ¨ {int(mean_sum-10)} åˆ° {int(mean_sum+10)} ä¹‹é—´çš„å·ç ç»„åˆ")
            
            # é€šç”¨å»ºè®®
            recommendations.extend([
                "å»ºè®®ç»“åˆå¤šç§åˆ†ææ–¹æ³•è¿›è¡Œé€‰å·",
                "æ³¨æ„å·ç åˆ†å¸ƒçš„å‡åŒ€æ€§ï¼Œé¿å…è¿‡äºé›†ä¸­",
                "å®šæœŸå…³æ³¨å·ç èµ°åŠ¿å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´ç­–ç•¥",
                "ç†æ€§æŠ•æ³¨ï¼Œåˆ‡å‹¿æ²‰è¿·"
            ])
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå»ºè®®å¤±è´¥: {e}")
            recommendations.append("åˆ†æå»ºè®®ç”Ÿæˆå¼‚å¸¸ï¼Œè¯·å‚è€ƒåŸºç¡€åˆ†æç»“æœ")
        
        return recommendations
    
    def _calculate_comprehensive_scores(self, analysis_results: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        scores = {
            'regularity_score': 50,    # è§„å¾‹æ€§è¯„åˆ†
            'randomness_score': 50,    # éšæœºæ€§è¯„åˆ†
            'hotness_score': 50,       # çƒ­åº¦è¯„åˆ†
            'stability_score': 50,     # ç¨³å®šæ€§è¯„åˆ†
            'overall_score': 50        # ç»¼åˆè¯„åˆ†
        }
        
        try:
            # åŸºäºå„é¡¹åˆ†æç»“æœè®¡ç®—è¯„åˆ†
            if 'frequency' in analysis_results and 'error' not in analysis_results['frequency']:
                # è§„å¾‹æ€§è¯„åˆ†åŸºäºé¢‘ç‡åˆ†å¸ƒçš„å‡åŒ€ç¨‹åº¦
                freq_result = analysis_results['frequency']
                if 'red_frequency' in freq_result:
                    freqs = list(freq_result['red_frequency'].values())
                    if freqs:
                        cv = np.std(freqs) / np.mean(freqs) if np.mean(freqs) > 0 else 1
                        scores['regularity_score'] = max(0, min(100, 100 - cv * 50))
            
            if 'statistical' in analysis_results and 'error' not in analysis_results['statistical']:
                # éšæœºæ€§è¯„åˆ†åŸºäºç»Ÿè®¡ç‰¹å¾
                stat_result = analysis_results['statistical']
                if stat_result.get('is_normal', False):
                    scores['randomness_score'] = 80
                else:
                    scores['randomness_score'] = 60
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            scores['overall_score'] = np.mean(list(scores.values()))
            
        except Exception as e:
            logger.error(f"è®¡ç®—è¯„åˆ†å¤±è´¥: {e}")
        
        return {k: round(v, 1) for k, v in scores.items()}
    
    def generate_analysis_report(self, lottery_type: str, period_range: str = "æœ€è¿‘100æœŸ") -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            lottery_type: å½©ç¥¨ç±»å‹
            period_range: æœŸæ•°èŒƒå›´
            
        Returns:
            åˆ†ææŠ¥å‘Šæ–‡æœ¬
        """
        try:
            # è·å–ç»¼åˆåˆ†æç»“æœ
            analysis_result = self.comprehensive_analysis(lottery_type, period_range)
            
            if 'error' in analysis_result:
                return f"âŒ åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {analysis_result['error']}"
            
            # ç”ŸæˆæŠ¥å‘Š
            report = f"""
ğŸ“Š {lottery_type}æ•°æ®åˆ†ææŠ¥å‘Š
{'='*60}

ğŸ¯ åˆ†ææ¦‚å†µ:
â€¢ å½©ç¥¨ç±»å‹: {lottery_type}
â€¢ åˆ†ææœŸæ•°: {period_range}
â€¢ æ•°æ®æ ·æœ¬: {analysis_result.get('data_count', 0)}æœŸ
â€¢ åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â€¢ ç½®ä¿¡åº¦è¯„åˆ†: {analysis_result.get('confidence_score', 0):.1f}/100

ğŸ“ˆ é¢‘ç‡åˆ†æ:
"""
            
            # æ·»åŠ é¢‘ç‡åˆ†æç»“æœ
            freq_result = analysis_result.get('frequency', {})
            if 'error' not in freq_result:
                if lottery_type == "åŒè‰²çƒ":
                    hot_red = freq_result.get('hot_red', [])
                    hot_blue = freq_result.get('hot_blue', [])
                    report += f"â€¢ çƒ­é—¨çº¢çƒ: {[f'{num}({freq}æ¬¡)' for num, freq in hot_red[:5]]}\n"
                    report += f"â€¢ çƒ­é—¨è“çƒ: {[f'{num}({freq}æ¬¡)' for num, freq in hot_blue[:3]]}\n"
                else:
                    hot_front = freq_result.get('hot_front', [])
                    hot_back = freq_result.get('hot_back', [])
                    report += f"â€¢ çƒ­é—¨å‰åŒº: {[f'{num}({freq}æ¬¡)' for num, freq in hot_front[:5]]}\n"
                    report += f"â€¢ çƒ­é—¨ååŒº: {[f'{num}({freq}æ¬¡)' for num, freq in hot_back[:3]]}\n"
            
            # æ·»åŠ å†·çƒ­å·åˆ†æ
            hot_cold_result = analysis_result.get('hot_cold', {})
            if 'error' not in hot_cold_result:
                report += f"\nğŸŒ¡ï¸ å†·çƒ­å·åˆ†æ:\n"
                hot_nums = hot_cold_result.get('hot', {})
                cold_nums = hot_cold_result.get('cold', {})
                if lottery_type == "åŒè‰²çƒ":
                    report += f"â€¢ çƒ­å·çº¢çƒ: {hot_nums.get('red', [])}\n"
                    report += f"â€¢ å†·å·çº¢çƒ: {cold_nums.get('red', [])}\n"
                else:
                    report += f"â€¢ çƒ­å·å‰åŒº: {hot_nums.get('front', [])}\n"
                    report += f"â€¢ å†·å·å‰åŒº: {cold_nums.get('front', [])}\n"
            
            # æ·»åŠ å’Œå€¼åˆ†æ
            sum_result = analysis_result.get('sum_analysis', {})
            if 'error' not in sum_result:
                report += f"\nâ• å’Œå€¼åˆ†æ:\n"
                report += f"â€¢ å¹³å‡å’Œå€¼: {sum_result.get('mean_sum', 0):.1f}\n"
                report += f"â€¢ å’Œå€¼èŒƒå›´: {sum_result.get('min_sum', 0)} - {sum_result.get('max_sum', 0)}\n"
                report += f"â€¢ å»ºè®®å’Œå€¼åŒºé—´: {sum_result.get('mean_sum', 0)-10:.0f} - {sum_result.get('mean_sum', 0)+10:.0f}\n"
            
            # æ·»åŠ é—æ¼åˆ†æ
            missing_result = analysis_result.get('missing', {})
            if 'error' not in missing_result:
                report += f"\nâ° é—æ¼åˆ†æ:\n"
                if lottery_type == "åŒè‰²çƒ":
                    high_missing = missing_result.get('high_missing_red', [])
                    max_missing = missing_result.get('max_red_missing', 0)
                    report += f"â€¢ æœ€å¤§é—æ¼: {max_missing}æœŸ\n"
                    report += f"â€¢ é«˜é—æ¼å·ç : {high_missing}\n"
            
            # æ·»åŠ ç»¼åˆè¯„åˆ†
            scores = analysis_result.get('scores', {})
            if scores:
                report += f"\nğŸ¯ ç»¼åˆè¯„åˆ†:\n"
                report += f"â€¢ è§„å¾‹æ€§: {scores.get('regularity_score', 0):.1f}/100\n"
                report += f"â€¢ éšæœºæ€§: {scores.get('randomness_score', 0):.1f}/100\n"
                report += f"â€¢ çƒ­åº¦æŒ‡æ•°: {scores.get('hotness_score', 0):.1f}/100\n"
                report += f"â€¢ ç¨³å®šæ€§: {scores.get('stability_score', 0):.1f}/100\n"
                report += f"â€¢ ç»¼åˆè¯„åˆ†: {scores.get('overall_score', 0):.1f}/100\n"
            
            # æ·»åŠ å»ºè®®
            recommendations = analysis_result.get('recommendations', [])
            if recommendations:
                report += f"\nğŸ’¡ åˆ†æå»ºè®®:\n"
                for i, rec in enumerate(recommendations, 1):
                    report += f"{i}. {rec}\n"
            
            # æ·»åŠ å…è´£å£°æ˜
            report += f"\nâš ï¸ é‡è¦æé†’:\n"
            report += "â€¢ æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•æ³¨å»ºè®®\n"
            report += "â€¢ å½©ç¥¨å…·æœ‰éšæœºæ€§ï¼Œå†å²æ•°æ®ä¸èƒ½é¢„æµ‹æœªæ¥ç»“æœ\n"
            report += "â€¢ è¯·ç†æ€§æŠ•æ³¨ï¼Œé‡åŠ›è€Œè¡Œ\n"
            report += "â€¢ æ•°æ®åˆ†ææœ‰åŠ©äºäº†è§£å†å²è§„å¾‹ï¼Œä½†ä¸ä¿è¯å‡†ç¡®æ€§\n"
            
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return f"âŒ åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_cache_key(self, lottery_type: str, period_range: str, analysis_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{lottery_type}_{period_range}_{analysis_type}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _update_memory_cache(self, cache_key: str, data: Any):
        """æ›´æ–°å†…å­˜ç¼“å­˜"""
        try:
            # æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œå¦‚æœè¶…è¿‡é™åˆ¶åˆ™æ¸…ç†æ—§ç¼“å­˜
            if len(self.memory_cache) >= self.cache_max_size:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = min(self.memory_cache.keys(), 
                               key=lambda k: self.memory_cache[k][1])
                del self.memory_cache[oldest_key]
            
            self.memory_cache[cache_key] = (data, datetime.now())
            
        except Exception as e:
            logger.warning(f"æ›´æ–°å†…å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _parallel_analysis(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """å¹¶è¡Œæ‰§è¡Œåˆ†æä»»åŠ¡"""
        analysis_results = {}
        
        # å®šä¹‰åˆ†æä»»åŠ¡
        analysis_tasks = [
            ('frequency', self._analyze_frequency),
            ('trend', self._analyze_trend),
            ('pattern', self._analyze_pattern),
            ('missing', self._analyze_missing),
            ('correlation', self._analyze_correlation),
            ('statistical', self._analyze_statistical),
            ('hot_cold', self._analyze_hot_cold),
            ('sum_analysis', self._analyze_sum),
            ('span', self._analyze_span),
            ('consecutive', self._analyze_consecutive),
            ('repeat', self._analyze_repeat),
            ('distribution', self._analyze_distribution_advanced),
            ('volatility', self._analyze_volatility),
            ('cycle', self._analyze_cycle_patterns)
        ]
        
        # æ™ºèƒ½é€‰æ‹©æ‰§è¡Œæ–¹å¼ï¼šæ•°æ®é‡å°æ—¶ä½¿ç”¨é¡ºåºæ‰§è¡Œï¼Œæ•°æ®é‡å¤§æ—¶ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œ
        data_size = len(history_data)
        use_parallel = data_size > 200 and len(analysis_tasks) > 8
        
        if use_parallel:
            try:
                with ThreadPoolExecutor(max_workers=min(self.max_workers, len(analysis_tasks))) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_analysis = {
                        executor.submit(analysis_func, history_data, lottery_type): analysis_name
                        for analysis_name, analysis_func in analysis_tasks
                    }
                    
                    # æ”¶é›†ç»“æœ
                    for future in as_completed(future_to_analysis):
                        analysis_name = future_to_analysis[future]
                        try:
                            result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                            analysis_results[analysis_name] = result
                        except Exception as e:
                            logger.error(f"å¹¶è¡Œæ‰§è¡Œ{analysis_name}åˆ†æå¤±è´¥: {e}")
                            analysis_results[analysis_name] = {'error': str(e)}
            
            except Exception as e:
                logger.error(f"å¹¶è¡Œåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
                use_parallel = False  # é™çº§åˆ°é¡ºåºæ‰§è¡Œ
        
        if not use_parallel:
            # é¡ºåºæ‰§è¡Œï¼ˆå°æ•°æ®é›†æˆ–å¹¶è¡Œå¤±è´¥æ—¶ï¼‰
            for analysis_name, analysis_func in analysis_tasks:
                try:
                    analysis_results[analysis_name] = analysis_func(history_data, lottery_type)
                except Exception as func_e:
                    logger.error(f"{analysis_name}åˆ†æå¤±è´¥: {func_e}")
                    analysis_results[analysis_name] = {'error': str(func_e)}
        
        return analysis_results
    
    def _analyze_distribution_advanced(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """é«˜çº§åˆ†å¸ƒåˆ†æ"""
        try:
            logger.info("å¼€å§‹è¿›è¡Œé«˜çº§åˆ†å¸ƒåˆ†æ...")
            
            all_numbers = []
            position_analysis = {}
            
            for data in history_data:
                red_balls, blue_balls = self._extract_numbers_from_data(data)
                if red_balls and blue_balls:
                    all_numbers.extend(red_balls)
                    
                    # æŒ‰ä½ç½®åˆ†æ
                    sorted_reds = sorted(red_balls)
                    for i, num in enumerate(sorted_reds):
                        if i not in position_analysis:
                            position_analysis[i] = []
                        position_analysis[i].append(num)
            
            if not all_numbers:
                return {'error': 'æ— æœ‰æ•ˆæ•°æ®è¿›è¡Œé«˜çº§åˆ†å¸ƒåˆ†æ'}
            
            # åˆ†å¸ƒç‰¹å¾åˆ†æ
            distribution_features = {
                'skewness': float(stats.skew(all_numbers)),  # ååº¦
                'kurtosis': float(stats.kurtosis(all_numbers)),  # å³°åº¦
                'entropy': self._calculate_entropy(all_numbers),  # ä¿¡æ¯ç†µ
                'uniformity_test': self._test_uniformity(all_numbers),  # å‡åŒ€æ€§æ£€éªŒ
                'position_preferences': {}  # ä½ç½®åå¥½
            }
            
            # ä½ç½®åå¥½åˆ†æ
            for position, nums in position_analysis.items():
                if nums:
                    distribution_features['position_preferences'][f'position_{position+1}'] = {
                        'mean': float(np.mean(nums)),
                        'std': float(np.std(nums)),
                        'most_common': Counter(nums).most_common(5)
                    }
            
            # åŒºåŸŸåˆ†å¸ƒåˆ†æ
            if lottery_type == "åŒè‰²çƒ":
                range_size = 33
            else:
                range_size = 35
            
            zone_size = range_size // 3
            zones = {
                'low': (1, zone_size),
                'middle': (zone_size + 1, zone_size * 2),
                'high': (zone_size * 2 + 1, range_size)
            }
            
            zone_distribution = {}
            for zone_name, (start, end) in zones.items():
                zone_count = sum(1 for num in all_numbers if start <= num <= end)
                zone_distribution[zone_name] = {
                    'count': zone_count,
                    'percentage': round((zone_count / len(all_numbers)) * 100, 2),
                    'range': f"{start}-{end}"
                }
            
            distribution_features['zone_distribution'] = zone_distribution
            
            return {
                'analysis_type': 'distribution_advanced',
                'distribution_features': distribution_features,
                'sample_size': len(all_numbers),
                'analysis_quality': 'high' if len(history_data) >= 100 else 'medium'
            }
            
        except Exception as e:
            logger.error(f"é«˜çº§åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_volatility(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """æ³¢åŠ¨æ€§åˆ†æ"""
        try:
            logger.info("å¼€å§‹è¿›è¡Œæ³¢åŠ¨æ€§åˆ†æ...")
            
            sums = []
            means = []
            ranges = []
            
            for data in history_data:
                red_balls, blue_balls = self._extract_numbers_from_data(data)
                if red_balls:
                    sums.append(sum(red_balls))
                    means.append(np.mean(red_balls))
                    ranges.append(max(red_balls) - min(red_balls))
            
            if len(sums) < 10:
                return {'error': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ³¢åŠ¨æ€§åˆ†æ'}
            
            # è®¡ç®—å„ç§æ³¢åŠ¨æ€§æŒ‡æ ‡
            volatility_metrics = {
                'sum_volatility': {
                    'std': float(np.std(sums)),
                    'cv': float(np.std(sums) / np.mean(sums)) if np.mean(sums) > 0 else 0,
                    'rolling_std': self._calculate_rolling_std(sums, window=10)
                },
                'mean_volatility': {
                    'std': float(np.std(means)),
                    'cv': float(np.std(means) / np.mean(means)) if np.mean(means) > 0 else 0,
                    'rolling_std': self._calculate_rolling_std(means, window=10)
                },
                'range_volatility': {
                    'std': float(np.std(ranges)),
                    'cv': float(np.std(ranges) / np.mean(ranges)) if np.mean(ranges) > 0 else 0,
                    'rolling_std': self._calculate_rolling_std(ranges, window=10)
                }
            }
            
            # æ³¢åŠ¨æ€§ç­‰çº§è¯„ä¼°
            sum_cv = volatility_metrics['sum_volatility']['cv']
            if sum_cv < 0.1:
                volatility_level = 'low'
            elif sum_cv < 0.2:
                volatility_level = 'medium'
            else:
                volatility_level = 'high'
            
            return {
                'analysis_type': 'volatility',
                'volatility_metrics': volatility_metrics,
                'volatility_level': volatility_level,
                'stability_score': round(1 / (1 + sum_cv), 3),
                'sample_size': len(sums)
            }
            
        except Exception as e:
            logger.error(f"æ³¢åŠ¨æ€§åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_cycle_patterns(self, history_data: List[Dict], lottery_type: str) -> Dict[str, Any]:
        """å‘¨æœŸæ¨¡å¼åˆ†æ"""
        try:
            logger.info("å¼€å§‹è¿›è¡Œå‘¨æœŸæ¨¡å¼åˆ†æ...")
            
            if len(history_data) < 30:
                return {'error': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‘¨æœŸæ¨¡å¼åˆ†æ'}
            
            # æŒ‰å¼€å¥–æ—¥æœŸåˆ†æå‘¨æœŸ
            date_patterns = {}
            number_cycles = defaultdict(list)
            
            for i, data in enumerate(history_data):
                red_balls, blue_balls = self._extract_numbers_from_data(data)
                if red_balls:
                    # è®°å½•æ¯ä¸ªå·ç çš„å‡ºç°ä½ç½®
                    for num in red_balls:
                        number_cycles[num].append(i)
                
                # æ—¥æœŸæ¨¡å¼åˆ†æ
                date_str = data.get('date', '')
                if date_str:
                    try:
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                        weekday = date_obj.strftime('%A')
                        month = date_obj.month
                        
                        if weekday not in date_patterns:
                            date_patterns[weekday] = {'count': 0, 'numbers': []}
                        date_patterns[weekday]['count'] += 1
                        date_patterns[weekday]['numbers'].extend(red_balls)
                    except:
                        continue
            
            # åˆ†æå·ç å‡ºç°å‘¨æœŸ
            cycle_analysis = {}
            for num, positions in number_cycles.items():
                if len(positions) >= 3:
                    intervals = [positions[i] - positions[i-1] for i in range(1, len(positions))]
                    cycle_analysis[num] = {
                        'avg_interval': round(np.mean(intervals), 2),
                        'std_interval': round(np.std(intervals), 2),
                        'last_appearance': positions[-1],
                        'predicted_next': positions[-1] + round(np.mean(intervals))
                    }
            
            # å‘¨æœŸå¼ºåº¦è¯„ä¼°
            cycle_strength = self._evaluate_cycle_strength(number_cycles, history_data)
            
            return {
                'analysis_type': 'cycle_patterns',
                'date_patterns': date_patterns,
                'number_cycles': dict(list(cycle_analysis.items())[:20]),  # å‰20ä¸ªå·ç 
                'cycle_strength': cycle_strength,
                'total_periods': len(history_data)
            }
            
        except Exception as e:
            logger.error(f"å‘¨æœŸæ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _extract_numbers_from_data(self, data: Dict) -> Tuple[List[int], List[int]]:
        """ä»æ•°æ®ä¸­æå–å·ç ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            numbers = data.get('numbers', {})
            if isinstance(numbers, str):
                numbers = json.loads(numbers)
            
            if isinstance(numbers, dict):
                if 'red' in numbers and 'blue' in numbers:
                    # åŒè‰²çƒæ ¼å¼
                    red_str = numbers.get('red', '')
                    blue_str = numbers.get('blue', '')
                    
                    red_balls = [int(x.strip()) for x in red_str.split(',') if x.strip().isdigit()]
                    blue_balls = [int(blue_str.strip())] if blue_str.strip().isdigit() else []
                    
                elif 'red_balls' in numbers and 'blue_balls' in numbers:
                    # æ ‡å‡†æ ¼å¼
                    red_balls = numbers.get('red_balls', [])
                    blue_balls = numbers.get('blue_balls', [])
                    
                elif 'front' in numbers and 'back' in numbers:
                    # å¤§ä¹é€æ ¼å¼
                    front_str = numbers.get('front', '')
                    back_str = numbers.get('back', '')
                    
                    red_balls = [int(x.strip()) for x in front_str.split(',') if x.strip().isdigit()]
                    blue_balls = [int(x.strip()) for x in back_str.split(',') if x.strip().isdigit()]
                    
                else:
                    return [], []
                
                return red_balls, blue_balls
            
            return [], []
            
        except Exception as e:
            logger.debug(f"æå–å·ç å¤±è´¥: {e}")
            return [], []
    
    def _calculate_entropy(self, numbers: List[int]) -> float:
        """è®¡ç®—ä¿¡æ¯ç†µ"""
        try:
            counter = Counter(numbers)
            total = len(numbers)
            entropy = 0
            
            for count in counter.values():
                probability = count / total
                if probability > 0:
                    entropy -= probability * math.log2(probability)
            
            return round(entropy, 4)
        except:
            return 0.0
    
    def _test_uniformity(self, numbers: List[int]) -> Dict[str, Any]:
        """å‡åŒ€æ€§æ£€éªŒ"""
        try:
            # å¡æ–¹æ£€éªŒ
            counter = Counter(numbers)
            observed = list(counter.values())
            expected = [len(numbers) / len(set(numbers))] * len(set(numbers))
            
            chi2_stat, p_value = stats.chisquare(observed, expected)
            
            return {
                'chi2_statistic': float(chi2_stat),
                'p_value': float(p_value),
                'is_uniform': p_value > 0.05,
                'confidence_level': '95%'
            }
        except Exception as e:
            return {'error': str(e)}
    
    def _calculate_rolling_std(self, values: List[float], window: int = 10) -> List[float]:
        """è®¡ç®—æ»šåŠ¨æ ‡å‡†å·®"""
        try:
            if len(values) < window:
                return []
            
            rolling_stds = []
            for i in range(window - 1, len(values)):
                window_values = values[i - window + 1:i + 1]
                rolling_stds.append(float(np.std(window_values)))
            
            return rolling_stds
        except:
            return []
    
    def _evaluate_cycle_strength(self, number_cycles: Dict, history_data: List[Dict]) -> Dict[str, Any]:
        """è¯„ä¼°å‘¨æœŸå¼ºåº¦"""
        try:
            cycle_scores = []
            
            for num, positions in number_cycles.items():
                if len(positions) >= 3:
                    intervals = [positions[i] - positions[i-1] for i in range(1, len(positions))]
                    cv = np.std(intervals) / np.mean(intervals) if np.mean(intervals) > 0 else float('inf')
                    
                    # å‘¨æœŸæ€§è¶Šå¼ºï¼Œå˜å¼‚ç³»æ•°è¶Šå°
                    cycle_score = 1 / (1 + cv) if cv != float('inf') else 0
                    cycle_scores.append(cycle_score)
            
            if cycle_scores:
                avg_cycle_strength = np.mean(cycle_scores)
                if avg_cycle_strength > 0.7:
                    strength_level = 'strong'
                elif avg_cycle_strength > 0.4:
                    strength_level = 'moderate'
                else:
                    strength_level = 'weak'
            else:
                avg_cycle_strength = 0
                strength_level = 'none'
            
            return {
                'average_strength': round(avg_cycle_strength, 3),
                'strength_level': strength_level,
                'numbers_with_cycles': len(cycle_scores)
            }
        except:
            return {'average_strength': 0, 'strength_level': 'unknown', 'numbers_with_cycles': 0}
    
    def _make_json_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, tuple):
            return list(obj)
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, bool):
            return obj
        elif isinstance(obj, (int, float, str, type(None))):
            return obj
        else:
            # å¯¹äºå…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return str(obj)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå®ä¾‹
    analyzer = LotteryAnalysis()
    
    # æ‰§è¡Œç»¼åˆåˆ†æ
    result = analyzer.comprehensive_analysis("åŒè‰²çƒ", "æœ€è¿‘100æœŸ")
    print("åˆ†æç»“æœ:", json.dumps(result, indent=2, ensure_ascii=False, default=str))
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = analyzer.generate_analysis_report("åŒè‰²çƒ", "æœ€è¿‘100æœŸ")
    print("\nåˆ†ææŠ¥å‘Š:")
    print(report)
